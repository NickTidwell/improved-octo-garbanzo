{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-04-12T13:05:47.636133Z","iopub.status.busy":"2023-04-12T13:05:47.634948Z","iopub.status.idle":"2023-04-12T13:05:49.052509Z","shell.execute_reply":"2023-04-12T13:05:49.051338Z","shell.execute_reply.started":"2023-04-12T13:05:47.636090Z"},"trusted":true},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","import os\n","import glob\n","from sklearn import cluster\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.linear_model import LinearRegression\n","from tqdm.auto import tqdm\n","base_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\n","\n","train_defog = glob.glob(base_path+'train/defog/**')\n","train_tdcsfog = glob.glob(base_path+'train/tdcsfog/**')\n","\n","subjects = pd.read_csv(base_path+'subjects.csv')\n","tasks = pd.read_csv(base_path+'tasks.csv')\n","sub = pd.read_csv(base_path+'sample_submission.csv')\n","\n","#Load All Data\n","tdcsfog_metadata=pd.read_csv(base_path+'tdcsfog_metadata.csv')\n","defog_metadata=pd.read_csv(base_path+'defog_metadata.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T13:05:49.063619Z","iopub.status.busy":"2023-04-12T13:05:49.062609Z","iopub.status.idle":"2023-04-12T13:05:49.250553Z","shell.execute_reply":"2023-04-12T13:05:49.249311Z","shell.execute_reply.started":"2023-04-12T13:05:49.063582Z"},"trusted":true},"outputs":[],"source":["args ={ 'NFOLD': 5,          \n","        'WINDOW': 5_000,     \n","        'STRIDE': 5_000,     \n","        'NSAMPLE' : 1000000, \n","       }\n","subjects.fillna(subjects.median(), inplace=True)\n","subjects.isnull().sum()\n","\n","tasks[\"Duration\"] = tasks[\"End\"] - tasks[\"Begin\"]\n","tasks = tasks.pivot_table(values='Duration', index='Id', columns='Task', aggfunc='sum', fill_value=0)\n","\n","def get_base_name(path):\n","    return os.path.basename(path).split('.')[0]\n","\n","tasks = tasks.reset_index()\n","task_predict_columns =tasks.columns[1:]\n","tasks['task_kmeans'] = cluster.KMeans(n_clusters=10, random_state=3).fit_predict(tasks[task_predict_columns])\n","\n","subect_predict_columns = subjects.columns[1:]\n","subjects['Sex'] = subjects['Sex'].astype('category').cat.codes\n","subjects['sub_kmeans'] = cluster.KMeans(n_clusters=10, random_state=3).fit_predict(subjects[subect_predict_columns])\n","\n","defog_metadata['Medication'] = defog_metadata['Medication'].astype('category').cat.codes\n","defog_metadata = defog_metadata.merge(subjects,how='left',on='Subject')\n","defog_train_files =[ get_base_name(file) for file in glob.glob(base_path+'train/defog/**')]\n","defog_meta_train = defog_metadata[defog_metadata['Id'].isin(defog_train_files)].reset_index(drop=True)\n","\n","\n","tdcsfog_metadata['Medication'] = tdcsfog_metadata['Medication'].astype('category').cat.codes\n","tdcsfog_metadata = tdcsfog_metadata.merge(subjects,how='left',on='Subject')\n","tdcsfog_train_files =[ get_base_name(file) for file in glob.glob(base_path+'train/tdcsfog/**')]\n","tdcsfog_meta_train = tdcsfog_metadata[tdcsfog_metadata['Id'].isin(tdcsfog_train_files)].reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T13:05:49.252754Z","iopub.status.busy":"2023-04-12T13:05:49.252302Z","iopub.status.idle":"2023-04-12T13:05:49.321598Z","shell.execute_reply":"2023-04-12T13:05:49.320585Z","shell.execute_reply.started":"2023-04-12T13:05:49.252707Z"},"trusted":true},"outputs":[],"source":["\n","\n","def format_input(df,f, mode):\n","    try:\n","        df[\"Id\"] = get_base_name(f)\n","        df['Time_frac']=(df.index/df.index.max()).values\n","        df = pd.merge(df, tasks[['Id','t_kmeans']], how='left', on='Id').fillna(-1)\n","        if mode == \"defog\":\n","            df = pd.merge(df, defog_metadata[['Id','Subject', 'Visit_x','Medication','s_kmeans']], how='left', on='Id').fillna(-1)\n","        elif mode == \"tdcsfog\":\n","            df = pd.merge( df, tdcsfog_metadata[['Id','Subject', 'Visit_x','Test','Medication','s_kmeans']], how='left', on='Id').fillna(-1)\n","        else: print(\"Error mode must be in 'defog' or 'tdcsfog' \")\n","        df_feats = fcollection.calculate(df, return_df=True, include_final_window=True, approve_sparsity=True, window_idx=\"begin\").astype(np.float32)\n","        df = df.merge(df_feats, how=\"left\", left_index=True, right_index=True)\n","        df.fillna(method=\"ffill\", inplace=True)\n","        return df\n","    except: pass\n","def data_loader(f, mode):\n","    try:\n","        df = pd.read_csv(f, index_col=\"Time\", usecols=['Time', 'AccV', 'AccML', 'AccAP', 'StartHesitation', 'Turn' , 'Walking'])\n","        df = format_input(df,f, mode)\n","        return df\n","    except: pass"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T13:05:49.323638Z","iopub.status.busy":"2023-04-12T13:05:49.323022Z","iopub.status.idle":"2023-04-12T13:17:17.946477Z","shell.execute_reply":"2023-04-12T13:17:17.944706Z","shell.execute_reply.started":"2023-04-12T13:05:49.323603Z"},"trusted":true},"outputs":[],"source":["\n","from sklearn.model_selection import GroupKFold\n","\n","choices = [1, 2, 3]\n","NFOLDS = args[\"NFOLD\"]\n","\n","def make_batch(mode):\n","    kfold = GroupKFold(NFOLDS)\n","    groups = None\n","    if(mode == \"defog\"):\n","        groups=kfold.split(defog_meta_train, groups=defog_meta_train.Subject)\n","    elif mode == \"tdcsfog\" :\n","        groups=kfold.split(tdcsfog_meta_train, groups=tdcsfog_meta_train.Subject)\n","    else: print(\"Error mode must be in 'defog' or 'tdcsfog' \")\n","    groups=list(groups)\n","\n","    batch_sizes = []\n","    total_records = 0\n","    for batch, group in enumerate(groups):\n","        batch_list = None\n","        if(mode == \"defog\"):\n","            batch_list = defog_meta_train.loc[group[1],['Id']].drop_duplicates().apply(\n","                lambda x:f\"{mode}/{x['Id']}.csv\",axis=1\n","            ).tolist()\n","        elif mode == \"tdcsfog\" :\n","            batch_list = tdcsfog_meta_train.loc[group[1],['Id']].drop_duplicates().apply(\n","                lambda x:f\"{mode}/{x['Id']}.csv\",axis=1\n","            ).tolist()\n","        else: print(\"Error mode must be in 'defog' or 'tdcsfog' \")\n","\n","        train_batch=pd.concat([data_loader(base_path + \"train/\" + file, mode) for file in tqdm(batch_list)])\n","        conditions = [\n","            (train_batch['StartHesitation'] == 1),\n","            (train_batch['Turn'] == 1),\n","            (train_batch['Walking'] == 1)]\n","\n","        train_batch['event'] = np.select(conditions, choices, default=0)\n","        train_batch['batch_id'] = batch\n","        batch_sizes.append(train_batch.shape[0])\n","        total_records = total_records + train_batch.shape[0]\n","        print(train_batch.shape)\n","        train_batch.to_parquet(f\"{mode}.pq\",partition_cols=['batch_id'])\n","    \n","    del train_batch\n","    del groups\n","    return [total_records - batch_size for batch_size in batch_sizes] #batch_sizes\n","\n","defog_batch_sizes = make_batch(\"defog\")\n","tdcsfog_batch_sizes = make_batch(\"tdcsfog\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T13:17:17.950226Z","iopub.status.busy":"2023-04-12T13:17:17.949488Z"},"trusted":true},"outputs":[],"source":["# #Used for Param Tuning\n","# !pip install optuna\n","# import optuna  \n","\n","# from sklearn.datasets import make_regression\n","# from sklearn.multioutput import MultiOutputRegressor\n","# from sklearn.linear_model import LinearRegression\n","# from sklearn.ensemble import GradientBoostingRegressor\n","# from sklearn.model_selection import cross_val_score, cross_validate \n","# from sklearn.metrics import mean_squared_error, average_precision_score\n","# from sklearn.model_selection import train_test_split\n","# from lightgbm import LGBMRegressor\n","# import lightgbm as lgb\n","# from optuna.integration import LightGBMPruningCallback\n","\n","# from sklearn.model_selection import GroupKFold\n","\n","\n","\n","\n","# pred_cols = ['StartHesitation', 'Turn' , 'Walking']    \n","\n","# def objective(trial):\n","#     lgbm_params ={\n","#             'boosting_type': 'gbdt',\n","#             'objective': 'multiclass',\n","#             'metric' : 'multi_logloss', \n","#             'early_stopping_round': 100,\n","#             'num_class' : 4, \n","#             'verbose': -1,\n","#             \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n","#             \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n","#             'num_iterations': trial.suggest_int(\"num_iterations\", 1000, 20000, step=500),\n","#             'max_bin': trial.suggest_int(\"max_bin\", 100, 255, step=20),\n","#             'num_leaves': trial.suggest_int(\"num_leaves\", 5, 31),\n","#             \"bagging_fraction\": trial.suggest_float(\n","#                 \"bagging_fraction\", 0.1, 1.0, step=0.1\n","#             ),\n","#             \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n","#             \"feature_fraction\": trial.suggest_float(\n","#                 \"feature_fraction\", 0.2, 0.95, step=0.1\n","#             ),\n","#             \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n","#             \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n","#            }\n","#     regressors = []\n","#     stats=[]\n","#     for batch in tqdm(range(1), total=1, desc=\"Folds\"):\n","#         #Set dynamic filters based on batch_id\n","#         train_filter = [[('batch_id','=',b)] for b in range(NFOLDS) if b != batch]\n","#         test_filter = [('batch_id','=',batch)]\n","\n","#         train=pd.read_parquet(f'{mode}.pq',filters=train_filter)\n","#         if(len(train) > args['NSAMPLE']):\n","#             train = train.sample(n=args['NSAMPLE']).reset_index(drop=True)\n","#         test=pd.read_parquet(f'{mode}.pq',filters=test_filter)\n","#         if(len(test) > args['NSAMPLE']):\n","#             test = test.sample(n=args['NSAMPLE']).reset_index(drop=True)\n","#         cols = train.columns.difference(['Id', 'Subject', 'Set', 'Time', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'Event', \"event\", \"batch_id\"]).tolist()\n","\n","#         y_test = test['event']\n","#         y_pcols = test[pred_cols]\n","#         X_test = test[cols]\n","#         train_set = lgb.Dataset(train[cols], label=train['event'])\n","#         test_set = lgb.Dataset(X_test, label=y_test, free_raw_data=False)\n","\n","#         lgbm_regress = lgb.train(\n","#             params = lgbm_params,\n","#             train_set = train_set,\n","#             valid_sets = [train_set, test_set],\n","#             callbacks=[\n","#                 LightGBMPruningCallback(trial, \"multi_logloss\", valid_name=\"valid_1\")\n","#             ],  \n","#             )\n","\n","#         regressors.append(lgbm_regress)\n","#         del train_set\n","#         cv=mean_squared_error(y_pcols, lgbm_regress.predict(X_test)[:,1:].clip(0.0,1.0))\n","#         stats.append(cv)\n","#         del test_set\n","#     return np.mean(stats)\n","\n","# mode = \"tdcsfog\" #defog\n","# study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n","# func = lambda trial: objective(trial)\n","# study.optimize(func, n_trials=50)\n","# for key, value in study.best_params.items():\n","#     print(f\"\\t\\t{key}: {value}\")\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-04-12T15:23:05.374898Z","iopub.status.busy":"2023-04-12T15:23:05.374063Z","iopub.status.idle":"2023-04-12T15:23:05.399968Z","shell.execute_reply":"2023-04-12T15:23:05.398535Z","shell.execute_reply.started":"2023-04-12T15:23:05.374846Z"},"trusted":true},"outputs":[],"source":["# #Used for Param Tuning\n","# !pip install optuna\n","# import optuna  \n","\n","# from sklearn.datasets import make_regression\n","# from sklearn.multioutput import MultiOutputRegressor\n","# from sklearn.linear_model import LinearRegression\n","# from sklearn.ensemble import GradientBoostingRegressor\n","# from sklearn.model_selection import cross_val_score, cross_validate \n","# from sklearn.metrics import mean_squared_error, average_precision_score\n","# from sklearn.model_selection import train_test_split\n","# from lightgbm import LGBMRegressor\n","# import lightgbm as lgb\n","# from optuna.integration import LightGBMPruningCallback\n","\n","# from sklearn.model_selection import GroupKFold\n","\n","\n","\n","\n","# pred_cols = ['StartHesitation', 'Turn' , 'Walking']    \n","\n","# def objective(trial):\n","#     lgbm_params ={\n","#             'boosting_type': 'gbdt',\n","#             'objective': 'multiclass',\n","#             'metric' : 'multi_logloss', \n","#             'early_stopping_round': 100,\n","#             'num_class' : 4, \n","#             'verbose': -1,\n","#             \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n","#             \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n","#             'num_iterations': trial.suggest_int(\"num_iterations\", 1000, 20000, step=500),\n","#             'max_bin': trial.suggest_int(\"max_bin\", 100, 255, step=20),\n","#             'num_leaves': trial.suggest_int(\"num_leaves\", 5, 31),\n","#             \"bagging_fraction\": trial.suggest_float(\n","#                 \"bagging_fraction\", 0.1, 1.0, step=0.1\n","#             ),\n","#             \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n","#             \"feature_fraction\": trial.suggest_float(\n","#                 \"feature_fraction\", 0.2, 0.95, step=0.1\n","#             ),\n","#             \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n","#             \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n","#            }\n","#     regressors = []\n","#     stats=[]\n","#     for batch in tqdm(range(1), total=1, desc=\"Folds\"):\n","#         #Set dynamic filters based on batch_id\n","#         train_filter = [[('batch_id','=',b)] for b in range(NFOLDS) if b != batch]\n","#         test_filter = [('batch_id','=',batch)]\n","\n","#         train=pd.read_parquet(f'{mode}.pq',filters=train_filter)\n","#         if(len(train) > args['NSAMPLE']):\n","#             train = train.sample(n=args['NSAMPLE']).reset_index(drop=True)\n","#         test=pd.read_parquet(f'{mode}.pq',filters=test_filter)\n","#         if(len(test) > args['NSAMPLE']):\n","#             test = test.sample(n=args['NSAMPLE']).reset_index(drop=True)\n","#         cols = train.columns.difference(['Id', 'Subject', 'Set', 'Time', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'Event', \"event\", \"batch_id\"]).tolist()\n","\n","#         y_test = test['event']\n","#         y_pcols = test[pred_cols]\n","#         X_test = test[cols]\n","#         train_set = lgb.Dataset(train[cols], label=train['event'])\n","#         test_set = lgb.Dataset(X_test, label=y_test, free_raw_data=False)\n","\n","#         lgbm_regress = lgb.train(\n","#             params = lgbm_params,\n","#             train_set = train_set,\n","#             valid_sets = [train_set, test_set],\n","#             callbacks=[\n","#                 LightGBMPruningCallback(trial, \"multi_logloss\", valid_name=\"valid_1\")\n","#             ],  \n","#             )\n","\n","#         regressors.append(lgbm_regress)\n","#         del train_set\n","#         cv=mean_squared_error(y_pcols, lgbm_regress.predict(X_test)[:,1:].clip(0.0,1.0))\n","#         stats.append(cv)\n","#         del test_set\n","#     return np.mean(stats)\n","\n","# mode = \"defog\" #defog\n","# study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Classifier\")\n","# func = lambda trial: objective(trial)\n","# study.optimize(func, n_trials=50)\n","# for key, value in study.best_params.items():\n","#     print(f\"\\t\\t{key}: {value}\")\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from sklearn.datasets import make_regression\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.model_selection import cross_val_score, cross_validate \n","from sklearn.metrics import mean_squared_error, average_precision_score\n","from sklearn.model_selection import train_test_split\n","from lightgbm import LGBMRegressor\n","import lightgbm as lgb\n","\n","from sklearn.model_selection import GroupKFold\n","\n","#default estimations\n","lgbm_params ={\n","        'boosting_type': 'gbdt',\n","        'objective': 'multiclass',\n","        'metric' : 'multi_logloss', \n","        'early_stopping_round': 100,\n","        'num_class' : 4, \n","#         'verbose': -1,\n","        \"learning_rate\":  0.2,\n","        \"max_depth\": 6,\n","        'num_iterations': 5000,\n","        'max_bin': 240,\n","        'num_leaves':12,\n","        \"bagging_fraction\": 0.75,\n","        \"bagging_freq\": 1,\n","        \"feature_fraction\": 0.50,\n","        \"lambda_l1\": 15,\n","        \"lambda_l2\": 90,\n","        'min_child_weight': 3.1,\n","        'extra_trees': True,\n","       }\n","\n","\n","\n","    \n","pred_cols = ['StartHesitation', 'Turn' , 'Walking']    \n","cols = None\n","defog_regressors = []\n","tdcsfog_regressors = []\n","\n","defog_stats=[]\n","tdcsfog_stats=[]\n","\n","def train_loop(mode):\n","    \n","    if(mode == \"defog\"):\n","        lgbm_params[\"learning_rate\"] =  0.15\n","        lgbm_params[\"max_depth\"] = 9\n","        lgbm_params['num_iterations'] = 13000\n","        lgbm_params['max_bin'] = 200\n","        lgbm_params['num_leaves'] = 26\n","        lgbm_params[\"bagging_fraction\"] = 0.2\n","        lgbm_params[\"bagging_freq\"] = 1\n","        lgbm_params[\"feature_fraction\"] = 0.8\n","        lgbm_params[\"lambda_l1\"] = 60\n","        lgbm_params[\"lambda_l2\"] = 45\n","\n","    elif mode == \"tdcsfog\" :\n","        lgbm_params[\"learning_rate\"] =  0.08\n","        lgbm_params[\"max_depth\"] = 6\n","        lgbm_params['num_iterations'] = 13000\n","        lgbm_params['max_bin'] = 220\n","        lgbm_params['num_leaves'] = 22\n","        lgbm_params[\"bagging_fraction\"] = 0.6\n","        lgbm_params[\"bagging_freq\"] = 1\n","        lgbm_params[\"feature_fraction\"] = 0.7\n","        lgbm_params[\"lambda_l1\"] = 40\n","        lgbm_params[\"lambda_l2\"] = 15\n","\n","    else: print(\"Error mode must be in 'defog' or 'tdcsfog' \")\n","        \n","    for batch in tqdm(range(NFOLDS), total=NFOLDS, desc=\"Folds\"):\n","\n","        #Set dynamic filters based on batch_id\n","        train_filter = [[('batch_id','=',b)] for b in range(NFOLDS) if b != batch]\n","        test_filter = [('batch_id','=',batch)]\n","        \n","#         iterations = None\n","#         MAX_ITERATIONS = 1\n","#         if(mode == \"defog\"):\n","#             iterations  = round(defog_batch_sizes[batch] / args['NSAMPLE'])\n","#         elif mode == \"tdcsfog\" :\n","#             iterations  = round(tdcsfog_regressors[batch] / args['NSAMPLE'])\n","#         else: print(\"Error mode must be in 'defog' or 'tdcsfog' \")\n","        \n","        iterations = 1\n","        for iter in range(iterations):\n","            last_iter = iter+1 == iterations\n","\n","            train=pd.read_parquet(f'{mode}.pq',filters=train_filter)\n","            if(len(train) > args['NSAMPLE']):\n","                train = train.sample(n=args['NSAMPLE']).reset_index(drop=True)\n","            test=pd.read_parquet(f'{mode}.pq',filters=test_filter)\n","            if(len(test) > args['NSAMPLE']):\n","                test = test.sample(n=args['NSAMPLE']).reset_index(drop=True)\n","            cols = train.columns.difference(['Id', 'Subject', 'Set', 'Time', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'Event', \"event\", \"batch_id\"]).tolist()\n","            train_set = lgb.Dataset(train[cols], label=train['event'])\n","            test_set = lgb.Dataset(test[cols], label=test['event'])\n","\n","            if ( iter == 0):\n","                lgbm_regress = lgb.train(\n","                    params = lgbm_params,\n","                    train_set = train_set,\n","                    valid_sets = [train_set, test_set],\n","                    keep_training_booster = True\n","                    )\n","            else:\n","                lgbm_regress = lgb.train(\n","                    params = lgbm_params,\n","                    train_set = train_set,\n","                    valid_sets = [train_set, test_set],\n","                    keep_training_booster = True,\n","                    init_model = lgbm_regress\n","                    )\n","            if(last_iter): \n","                if(mode == \"defog\"):\n","                    defog_regressors.append(lgbm_regress)\n","                elif mode == \"tdcsfog\" :\n","                    tdcsfog_regressors.append(lgbm_regress)\n","                else: print(\"Error mode must be in 'defog' or 'tdcsfog' \")\n","                \n","            del train_set\n","            del test_set\n","#Train two models\n","train_loop(\"tdcsfog\")\n","train_loop(\"defog\")\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","submissions = []\n","out_cols = ['Id', 'StartHesitation', 'Turn' , 'Walking']\n","defog_test_inputs = glob.glob(base_path+'test/defog/**')\n","tdcsfog_test_inputs = glob.glob(base_path+'test/tdcsfog/**')\n","\n","def regressor_mean(regressor):\n","    pred_vals = []\n","    for i, reg in enumerate(regressor):\n","        y_pred = reg.predict(df[cols])[:,1:]\n","        y_pred = np.round(y_pred.clip(0.0,1.0),3)\n","        pred_vals.append(np.expand_dims(y_pred,axis=2))\n","    return np.mean(np.concatenate(pred_vals,axis=2),axis=2)\n","\n","for file in defog_test_inputs: \n","    df = pd.read_csv(file)\n","    df.set_index('Time', drop=True, inplace=True)\n","    df = format_input(df,file, \"defog\")\n","    cols = df.columns.difference(['Id', 'Subject', 'Set', 'Time', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'Event', \"event\", \"batch_id\"]).tolist()\n","    combine_res = pd.DataFrame( regressor_mean(defog_regressors) , columns=pred_cols)\n","    df = pd.concat([df,combine_res], axis=1)\n","    df['Id'] = df['Id'].astype(str) + '_' + df.index.astype(str)\n","    submissions.append(df[out_cols])\n","for file in tdcsfog_test_inputs: \n","    df = pd.read_csv(file)\n","    df.set_index('Time', drop=True, inplace=True)\n","    df = format_input(df,file, \"tdcsfog\")\n","    cols = df.columns.difference(['Id', 'Subject', 'Set', 'Time', 'StartHesitation', 'Turn', 'Walking', 'Valid', 'Task', 'Event', \"event\", \"batch_id\"]).tolist()\n","    combine_res = pd.DataFrame( regressor_mean(tdcsfog_regressors) , columns=pred_cols)\n","    df = pd.concat([df,combine_res], axis=1)\n","    df['Id'] = df['Id'].astype(str) + '_' + df.index.astype(str)\n","    submissions.append(df[out_cols])\n","sub['t'] = 0\n","submissions = pd.concat(submissions)\n","submissions = pd.merge(sub[['Id']], submissions, how='left', on='Id').fillna(0.0)\n","submissions[out_cols].to_csv('submission.csv', index=False)\n","submissions"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
